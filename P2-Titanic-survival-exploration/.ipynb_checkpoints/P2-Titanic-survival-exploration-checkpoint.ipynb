{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arjan Hada\n",
    "<br\\>hadaarjan@gmail.com                             \n",
    "\n",
    "*Click on the icon on right for visualizing dynamic plots, if viewing on github.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1912, the largest ship afloat at the time- RMS titanic sank after colliding with an iceberg. Of the 2224 passengers and crew abroad 1502 died. \n",
    "\n",
    "In this project, we will explore the training dataset (train) from [kaggle](https://www.kaggle.com/c/titanic/data). This dataset contains demographic and passenger information about 891 of the 2224 passengers and crew abroad. The most interesting question here is what features made people more likely to survive the sinking? Based on the available feature information can we build a classification algorithm that can reasonably predict survival? \n",
    "\n",
    "I will start my analysis by exploring individual features, and combination of features to see how they correlate to survival. To make the analysis vivid, I will use the interactive plotting library - [plotly](https://plot.ly/python/) (**Take the mouse cursor to the plots for interactivity**). Finally, I will build a logarithmic regression and random forest model to predict survival; and evaluate the accuracy of the model.\n",
    "\n",
    "In the dataframe, each row represents a passenger on the Titanic, and each column represents some information about them. Let's take a look at what the columns represents:\n",
    "\n",
    "- **Survived**: Outcome of survival (0 = No; 1 = Yes)\n",
    "- **Pclass**: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)\n",
    "- **Name**: Name of passenger\n",
    "- **Sex**: Sex of the passenger\n",
    "- **Age**: Age of the passenger (Some entries contain `NaN`)\n",
    "- **SibSp**: Number of siblings and spouses of the passenger aboard\n",
    "- **Parch**: Number of parents and children of the passenger aboard\n",
    "- **Ticket**: Ticket number of the passenger\n",
    "- **Fare**: Fare paid by the passenger\n",
    "- **Cabin** Cabin number of the passenger (Some entries contain `NaN`)\n",
    "- **Embarked**: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.tools import FigureFactory as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also do offline plotting using plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "\n",
    "# Initiate the Plotly Notebook mode for plotting graphs offline inside a Jupyter Notebook Environment\n",
    "#Run at the start of every ipython notebook to use plotly.offline. \n",
    "#This injects the plotly.js source files into the notebook.\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using boxplot a lot. Below, I define a function to plot boxplot using plotly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotly_barplot(x0, y0, ylab, ptitle):\n",
    "    \"\"\"Plots interactive barplot using plotly.\n",
    "       x0 is a list representing names of each bar e.g.['male', 'female'].\n",
    "       y0 is a list representing values for each bar e.g. [0.18, 0.74].\n",
    "    \"\"\"\n",
    "    data = [go.Bar(\n",
    "            x=x0,\n",
    "            y=y0\n",
    "        )]\n",
    "    layout = go.Layout(autosize = False, width = 400, height = 400,\n",
    "                  yaxis = dict(title = ylab),\n",
    "                  title = ptitle)\n",
    "    fig = go.Figure(data = data, layout = layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the titanic train dataset to create dataFrame\n",
    "train_data = \"train.csv\"\n",
    "train = pd.read_csv(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the `head` of the dataframe\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on with the actual analysis, we will use pandas .shape and .describe() method to understand our data better. We will also examine how well individual features- like Sex, Age, Pclass, Fare, Port of embarkation predict survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 12)\n"
     ]
    }
   ],
   "source": [
    "print train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the distribution of survival look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"d657ff3c-7f47-4960-a0a8-77bf2a43c4e3\" style=\"height: 400px; width: 400px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d657ff3c-7f47-4960-a0a8-77bf2a43c4e3\", [{\"x\": [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], \"type\": \"histogram\", \"histnorm\": \"probability\"}], {\"autosize\": false, \"yaxis\": {\"title\": \"Normalized Counts\"}, \"title\": \"Distribution of Survival, (1 = Survived)\", \"height\": 400, \"width\": 400, \"bargap\": 0.5}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Passengers that survived vs passengers that passed away\n",
    "survival_hist = [\n",
    "    go.Histogram(x=train['Survived'],\n",
    "                histnorm = 'probability'\n",
    "                )\n",
    "]\n",
    "layout = go.Layout(autosize = False, width = 400, height = 400, bargap = 0.5,\n",
    "                  yaxis = dict(title = 'Normalized Counts'),\n",
    "                  title = 'Distribution of Survival, (1 = Survived)')\n",
    "fig0 = go.Figure(data=survival_hist, layout = layout)\n",
    "iplot(fig0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of passengers (61.6%) didn't survive the sinking ship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Who was more likely to survive female or Male?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"665966fe-9926-4c0f-831c-fa575cb8b0c1\" style=\"height: 400px; width: 400px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"665966fe-9926-4c0f-831c-fa575cb8b0c1\", [{\"y\": [0.18890814558058924, 0.7420382165605095], \"x\": [\"male\", \"female\"], \"type\": \"bar\"}], {\"height\": 400, \"width\": 400, \"autosize\": false, \"yaxis\": {\"title\": \"Survival Rates\"}, \"title\": \"Survival by Sex\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized male survival\n",
    "male_survival = train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)\n",
    "# Normalized female survival\n",
    "female_survival = train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)\n",
    "\n",
    "# Survival by Sex\n",
    "x0 = ['male', 'female']\n",
    "y0 = [male_survival[1], female_survival[1]]\n",
    "plotly_barplot(x0, y0, ylab = 'Survival Rates', ptitle = 'Survival by Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the survival statistics, 74.2% of all females from the dataset survived the ship sinking, whereas only 18.9% of males survived the ship sinking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the distribution of age look among survivors and non-survivors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's logical to think that children were saved first. Age could be another variable to predict survival. We will handle missing values with Age in the later section - Clean and format the data. For now, missing values have been excluded from the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"489f20b2-4164-4cbb-af30-7bb7cf72006e\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"489f20b2-4164-4cbb-af30-7bb7cf72006e\", [{\"x\": [22.0, 35.0, null, 54.0, 2.0, 20.0, 39.0, 14.0, 2.0, 31.0, 35.0, 8.0, null, 19.0, null, 40.0, 66.0, 28.0, 42.0, 21.0, 18.0, 40.0, 27.0, null, null, null, null, 18.0, 7.0, 21.0, 65.0, 28.5, 11.0, 22.0, 45.0, 4.0, null, 19.0, 26.0, 32.0, 16.0, 21.0, 26.0, 25.0, null, null, 22.0, 28.0, 16.0, null, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 38.0, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 54.0, null, 45.0, 33.0, 20.0, 47.0, 25.0, 23.0, 37.0, 16.0, 24.0, null, 19.0, 18.0, 19.0, 9.0, 36.5, 42.0, 51.0, 55.5, 40.5, null, 51.0, 30.0, null, null, 44.0, 26.0, 17.0, 1.0, 45.0, null, 28.0, 61.0, 4.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, null, 40.0, 36.0, 19.0, null, 42.0, 24.0, 28.0, null, 34.0, 45.5, 2.0, 32.0, 24.0, 22.0, 30.0, null, 42.0, 30.0, 27.0, 51.0, null, 22.0, 20.5, 18.0, null, 29.0, 59.0, 24.0, null, 44.0, 19.0, 33.0, null, 29.0, 22.0, 30.0, 44.0, 25.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, null, 52.0, 40.0, null, 36.0, 16.0, null, 37.0, 45.0, null, 7.0, 65.0, 28.0, 16.0, null, 33.0, 22.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, 19.0, null, 30.0, 26.0, 28.0, 43.0, 54.0, 22.0, 27.0, null, 61.0, 45.5, 38.0, 16.0, null, 29.0, 45.0, 28.0, 25.0, 36.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 38.0, 40.0, 29.0, 45.0, 35.0, null, 30.0, 18.0, 19.0, 22.0, 3.0, 27.0, 20.0, 19.0, 32.0, null, 18.0, 1.0, null, 28.0, 22.0, 31.0, 46.0, 23.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 21.0, null, null, null, null, null, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, null, 17.0, 50.0, 21.0, 64.0, 31.0, 20.0, 25.0, 36.0, null, 30.0, null, 65.0, null, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, null, 38.0, 22.0, null, 34.0, 29.0, 22.0, 9.0, null, 50.0, null, 58.0, 30.0, null, 21.0, 55.0, 71.0, 21.0, null, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 18.0, 28.0, null, 24.0, 47.0, null, 32.0, 22.0, null, null, 40.5, null, 39.0, 23.0, null, 17.0, 30.0, 45.0, null, 9.0, 11.0, 50.0, 64.0, 33.0, 27.0, null, 62.0, null, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 16.0, 19.0, null, 54.0, 36.0, null, 47.0, 22.0, null, 35.0, 47.0, null, 37.0, 36.0, 49.0, null, null, null, 44.0, 36.0, 30.0, 39.0, null, null, 35.0, 34.0, 26.0, 26.0, 27.0, 21.0, 21.0, 61.0, 57.0, 26.0, null, 51.0, null, 9.0, 32.0, 31.0, 41.0, null, 20.0, 2.0, 19.0, null, null, 21.0, 18.0, 24.0, null, 32.0, 23.0, 58.0, 40.0, 47.0, 36.0, 32.0, 25.0, null, 43.0, 31.0, 70.0, null, 18.0, 24.5, 43.0, null, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 25.0, 60.0, 52.0, 44.0, 49.0, 42.0, 18.0, 25.0, 26.0, 39.0, null, 29.0, 52.0, 19.0, null, 33.0, 17.0, 34.0, 50.0, 20.0, 25.0, 25.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, null, null, 36.0, 24.0, 70.0, 16.0, 19.0, 31.0, 33.0, 23.0, 28.0, 18.0, 34.0, null, 41.0, 16.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 18.0, null, null, 29.0, null, 25.0, 25.0, 8.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 30.0, 30.0, 34.0, 31.0, 39.0, 18.0, 39.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 38.0, 2.0, null, null, null, 23.0, 18.0, 21.0, null, 20.0, 16.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, 4.0, 74.0, 9.0, 44.0, null, 41.0, 21.0, null, 24.0, 31.0, null, 26.0, 33.0, 47.0, 20.0, 19.0, null, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, null, 32.0], \"type\": \"box\", \"name\": \"deceased\"}, {\"x\": [38.0, 26.0, 35.0, 27.0, 14.0, 4.0, 58.0, 55.0, null, null, 34.0, 15.0, 28.0, 38.0, null, null, null, null, 14.0, 3.0, 19.0, null, 49.0, 29.0, null, 21.0, 5.0, 38.0, null, 29.0, 17.0, 32.0, 0.83, 30.0, 29.0, null, 17.0, 33.0, 23.0, 23.0, 34.0, 21.0, null, null, 32.5, 12.0, 24.0, null, 29.0, 19.0, 22.0, 24.0, 27.0, 22.0, 16.0, 40.0, 9.0, null, 1.0, 1.0, 4.0, null, 45.0, 32.0, 19.0, 3.0, 44.0, 58.0, null, 18.0, 26.0, 16.0, 40.0, 35.0, 31.0, 27.0, 32.0, 16.0, 38.0, 19.0, 35.0, 5.0, 8.0, null, 24.0, 37.0, 29.0, null, 30.0, 35.0, 50.0, 3.0, 25.0, 58.0, 35.0, 25.0, 41.0, null, 63.0, 35.0, 19.0, 30.0, 42.0, 22.0, 26.0, 19.0, null, 50.0, null, null, null, 0.92, null, 17.0, 30.0, 24.0, 18.0, 26.0, 24.0, 31.0, 40.0, 30.0, 22.0, 36.0, 36.0, 31.0, 16.0, null, null, 41.0, 45.0, 2.0, 24.0, 24.0, 40.0, null, 3.0, 22.0, null, null, 60.0, null, null, 24.0, 25.0, null, 22.0, 42.0, 1.0, 35.0, 36.0, 17.0, 36.0, 21.0, 23.0, 24.0, 28.0, 39.0, 3.0, 33.0, 44.0, 34.0, 18.0, 28.0, 19.0, 32.0, 28.0, null, 42.0, 14.0, 24.0, 45.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 49.0, 29.0, null, 50.0, 48.0, 0.75, 33.0, 23.0, 2.0, 63.0, 25.0, 35.0, 9.0, 54.0, 16.0, 33.0, null, 26.0, 29.0, 36.0, 54.0, 34.0, 36.0, 30.0, 44.0, 50.0, 2.0, null, 7.0, 30.0, 22.0, 36.0, 32.0, 19.0, null, 8.0, 17.0, 22.0, 22.0, 48.0, 39.0, 36.0, 32.0, 62.0, 53.0, 36.0, null, 34.0, 39.0, 32.0, 25.0, 39.0, 18.0, 60.0, 52.0, null, 49.0, 24.0, 35.0, 27.0, 22.0, 40.0, null, 24.0, 4.0, 42.0, 20.0, 21.0, 80.0, 32.0, 28.0, 24.0, null, 0.75, 48.0, 56.0, 23.0, 18.0, null, 50.0, 20.0, null, 40.0, 31.0, 18.0, 36.0, 27.0, 15.0, 31.0, 4.0, null, null, 18.0, 35.0, 45.0, 42.0, 22.0, null, 24.0, 48.0, 38.0, 27.0, 6.0, 27.0, 30.0, null, 29.0, 35.0, null, 21.0, 31.0, 30.0, 4.0, 6.0, 48.0, 0.67, 33.0, 20.0, 36.0, 51.0, 54.0, 5.0, 43.0, 13.0, 17.0, 18.0, 1.0, 49.0, 31.0, 31.0, 11.0, 0.42, 27.0, 33.0, 52.0, 27.0, 27.0, 1.0, null, 62.0, 15.0, 0.83, 39.0, 32.0, null, 30.0, null, 16.0, 18.0, 45.0, 51.0, 24.0, 48.0, 42.0, 27.0, 4.0, 47.0, 28.0, 15.0, 56.0, 25.0, 19.0, 26.0], \"type\": \"box\", \"name\": \"survived\"}], {\"xaxis\": {\"title\": \"Age\"}, \"title\": \"Survival by Age\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Age distribution of those who passed away\n",
    "ages_deceased = train[\"Age\"][train[\"Survived\"] == 0]\n",
    "\n",
    "#Age distribution of survivors\n",
    "ages_survived = train[\"Age\"][train[\"Survived\"] == 1]\n",
    "\n",
    "#Boxplot to show age distribution of deceased vs survived\n",
    "trace_deceased = go.Box(x = ages_deceased, name = \"deceased\")\n",
    "trace_survived = go.Box(x = ages_survived, name = \"survived\")\n",
    "survival_by_age_data = [trace_deceased, trace_survived]\n",
    "layout = go.Layout(xaxis = dict(title = 'Age'),title = \"Survival by Age\")\n",
    "fig2 = go.Figure(data=survival_by_age_data, layout=layout)\n",
    "iplot(fig2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The age distribution for those who survived is shifted more towards the left. Albeit modestly, age does seem to correlate with survival. We will further test this assumption by creating a \"child\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does survival rate change across Pclass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also logical to think that passenger class might affect the outcome, as first class cabins were closer to the deck of the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"d34fb7a9-aa25-422a-8085-13f790afa592\" style=\"height: 400px; width: 400px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d34fb7a9-aa25-422a-8085-13f790afa592\", [{\"y\": [0.6296296296296297, 0.47282608695652173, 0.24236252545824846], \"x\": [\"Pclass 1\", \"Pclass 2\", \"Pclass 3\"], \"type\": \"bar\"}], {\"height\": 400, \"width\": 400, \"autosize\": false, \"yaxis\": {\"title\": \"Survival Rates\"}, \"title\": \"Survival by Pclass\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized Pclass survival\n",
    "Pclass1 = train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)\n",
    "Pclass2 = train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)\n",
    "Pclass3 = train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)\n",
    "\n",
    "# Survival by Pclass- Barplot\n",
    "x0 = ['Pclass 1', 'Pclass 2', 'Pclass 3']\n",
    "y0 = [Pclass1[1], Pclass2[1], Pclass3[1]]\n",
    "\n",
    "plotly_barplot(x0, y0, ylab = 'Survival Rates', ptitle = 'Survival by Pclass')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining the survival statistics, survival rates for Pclass1 > Pclass2 > Pclass3. 63%, 47.3% and 24.2% of Pclass1, Pclass2 and Pclass3 survived respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does the distribution of fare look among survivors and non-survivors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare is highly correlated with Pclass. It could be another variable to influence survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"d73cc14d-c703-44f3-855e-e05024d65816\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"d73cc14d-c703-44f3-855e-e05024d65816\", [{\"x\": [7.25, 8.05, 8.4583, 51.8625, 21.075, 8.05, 31.275, 7.8542, 29.125, 18.0, 26.0, 21.075, 7.225, 263.0, 7.8958, 27.7208, 10.5, 82.1708, 52.0, 8.05, 18.0, 9.475, 21.0, 7.8958, 8.05, 15.5, 21.6792, 17.8, 39.6875, 7.8, 61.9792, 7.2292, 46.9, 7.2292, 83.475, 27.9, 27.7208, 8.1583, 8.6625, 10.5, 46.9, 73.5, 14.4542, 7.65, 7.8958, 8.05, 9.0, 47.1, 34.375, 8.05, 8.05, 8.05, 7.8542, 61.175, 20.575, 7.25, 8.05, 34.6542, 26.0, 7.8958, 7.8958, 77.2875, 8.6542, 7.925, 7.8958, 7.8958, 52.0, 14.4542, 8.05, 9.825, 14.4583, 7.925, 7.75, 21.0, 247.5208, 31.275, 73.5, 8.05, 30.0708, 77.2875, 7.75, 6.975, 7.8958, 7.05, 14.5, 13.0, 15.0458, 53.1, 9.2167, 79.2, 15.2458, 6.75, 11.5, 36.75, 34.375, 26.0, 13.0, 12.525, 8.05, 14.5, 7.3125, 61.3792, 8.05, 8.6625, 69.55, 16.1, 7.775, 8.6625, 39.6875, 27.9, 25.925, 56.4958, 33.5, 29.125, 7.925, 30.6958, 7.8542, 25.4667, 28.7125, 13.0, 0.0, 69.55, 15.05, 31.3875, 50.0, 15.5, 7.8958, 13.0, 7.75, 8.4042, 13.0, 9.5, 69.55, 6.4958, 7.225, 10.4625, 15.85, 7.05, 7.25, 13.0, 7.75, 27.0, 10.5, 13.0, 8.05, 7.8958, 9.35, 7.25, 13.0, 25.4667, 7.775, 13.5, 10.5, 7.55, 26.0, 10.5, 12.275, 14.4542, 10.5, 7.125, 7.225, 90.0, 7.775, 26.0, 7.25, 10.4625, 26.55, 16.1, 20.2125, 7.75, 79.65, 0.0, 7.75, 10.5, 39.6875, 31.0, 29.7, 7.75, 0.0, 29.125, 7.75, 7.8542, 9.5, 26.0, 8.6625, 7.8958, 12.875, 8.85, 7.8958, 27.7208, 7.2292, 151.55, 0.0, 8.05, 24.0, 26.0, 7.8958, 26.25, 14.0, 7.25, 7.8958, 69.55, 6.2375, 28.5, 153.4625, 18.0, 7.8958, 66.6, 35.5, 13.0, 13.0, 13.0, 8.6625, 9.225, 35.0, 7.2292, 17.8, 7.225, 9.5, 13.0, 27.9, 27.7208, 14.4542, 7.05, 15.5, 7.25, 6.4958, 8.05, 135.6333, 21.075, 211.5, 4.0125, 7.775, 7.925, 7.8958, 73.5, 46.9, 7.7292, 7.925, 7.7958, 7.8542, 26.0, 10.5, 8.05, 9.825, 15.85, 8.6625, 21.0, 7.75, 7.775, 25.4667, 7.8958, 6.8583, 0.0, 8.05, 13.0, 24.15, 7.8958, 7.7333, 7.875, 14.4, 20.2125, 7.25, 7.75, 7.125, 55.9, 34.375, 263.0, 10.5, 9.5, 7.775, 27.75, 19.9667, 27.75, 8.05, 26.55, 7.75, 8.05, 38.5, 13.0, 8.05, 7.05, 0.0, 26.55, 7.725, 7.25, 8.6625, 9.8375, 52.0, 21.0, 7.0458, 7.5208, 46.9, 0.0, 8.05, 25.4667, 29.7, 8.05, 19.9667, 7.25, 30.5, 49.5042, 8.05, 14.4583, 15.1, 151.55, 7.7958, 8.6625, 7.75, 7.6292, 9.5875, 108.9, 22.525, 8.05, 7.4958, 34.0208, 24.15, 7.8958, 7.8958, 7.225, 7.2292, 7.75, 221.7792, 7.925, 11.5, 7.2292, 7.2292, 8.6625, 26.55, 14.5, 31.275, 31.275, 106.425, 26.0, 20.525, 26.0, 7.8292, 26.55, 227.525, 7.75, 7.8958, 13.5, 8.05, 8.05, 24.15, 7.8958, 21.075, 7.2292, 8.05, 14.5, 14.4583, 26.0, 40.125, 8.7125, 15.0, 8.05, 8.05, 7.125, 7.25, 7.75, 26.0, 24.15, 0.0, 7.225, 7.8958, 42.4, 8.05, 15.55, 7.8958, 31.275, 7.05, 7.75, 8.05, 14.4, 16.1, 10.5, 14.4542, 7.8542, 16.1, 32.3208, 12.35, 7.8958, 7.7333, 7.0542, 0.0, 27.9, 7.925, 26.25, 39.6875, 16.1, 7.8542, 27.9, 7.8958, 7.55, 7.8958, 8.4333, 6.75, 73.5, 7.8958, 15.5, 13.0, 113.275, 7.225, 25.5875, 7.4958, 73.5, 13.0, 7.775, 8.05, 52.0, 10.5, 0.0, 7.775, 8.05, 46.9, 8.1375, 9.225, 46.9, 39.0, 41.5792, 39.6875, 10.1708, 7.7958, 7.225, 26.55, 13.5, 8.05, 110.8833, 7.65, 14.4542, 7.7417, 7.8542, 26.0, 26.55, 9.4833, 13.0, 7.65, 15.5, 7.775, 7.0542, 13.0, 13.0, 8.6625, 26.0, 7.925, 18.7875, 0.0, 13.0, 13.0, 16.1, 34.375, 7.8958, 7.8958, 78.85, 16.1, 71.0, 20.25, 53.1, 7.75, 9.5, 7.8958, 7.7958, 11.5, 8.05, 14.5, 7.125, 7.775, 39.6, 7.75, 24.15, 8.3625, 9.5, 7.8542, 10.5, 7.225, 7.75, 7.75, 7.7375, 30.0, 23.45, 7.05, 7.25, 29.125, 79.2, 7.75, 26.0, 69.55, 30.6958, 7.8958, 13.0, 7.2292, 24.15, 13.0, 7.775, 0.0, 7.775, 13.0, 7.8875, 24.15, 10.5, 31.275, 8.05, 0.0, 7.925, 37.0042, 6.45, 27.9, 0.0, 39.6875, 6.95, 56.4958, 7.2292, 7.8542, 8.3, 8.6625, 8.05, 7.925, 10.5, 6.4375, 8.6625, 7.55, 69.55, 7.8958, 33.0, 31.275, 7.775, 15.2458, 26.0, 7.2292, 14.1083, 11.5, 69.55, 13.0, 50.4958, 9.5, 7.8958, 5.0, 9.0, 9.8458, 7.8958, 7.8958, 7.8958, 10.5167, 10.5, 7.05, 29.125, 13.0, 23.45, 7.75], \"type\": \"box\", \"name\": \"deceased\"}, {\"x\": [71.2833, 7.925, 53.1, 11.1333, 30.0708, 16.7, 26.55, 16.0, 13.0, 7.225, 13.0, 8.0292, 35.5, 31.3875, 7.8792, 146.5208, 7.75, 7.2292, 11.2417, 41.5792, 7.8792, 7.75, 76.7292, 26.0, 35.5, 10.5, 27.75, 80.0, 15.2458, 10.5, 7.925, 56.4958, 29.0, 12.475, 9.5, 7.7875, 10.5, 15.85, 263.0, 63.3583, 23.0, 7.65, 7.775, 24.15, 13.0, 11.2417, 7.1417, 22.3583, 26.0, 26.2833, 7.75, 15.85, 7.7958, 66.6, 7.7333, 15.75, 20.525, 55.0, 11.1333, 39.0, 22.025, 15.5, 26.55, 13.0, 7.8542, 26.0, 27.7208, 146.5208, 7.75, 8.05, 18.7875, 7.75, 31.0, 21.0, 113.275, 7.925, 76.2917, 8.05, 90.0, 10.5, 83.475, 31.3875, 26.25, 15.5, 14.5, 52.5542, 15.2458, 79.2, 86.5, 512.3292, 26.0, 31.3875, 7.775, 153.4625, 135.6333, 0.0, 19.5, 7.75, 77.9583, 20.25, 8.05, 9.5, 13.0, 7.75, 78.85, 91.0792, 30.5, 247.5208, 7.75, 23.25, 12.35, 151.55, 110.8833, 108.9, 56.9292, 83.1583, 262.375, 7.8542, 26.0, 164.8667, 134.5, 12.35, 29.0, 135.6333, 13.0, 20.525, 57.9792, 23.25, 133.65, 134.5, 8.05, 26.0, 263.0, 13.0, 13.0, 16.1, 15.9, 55.0, 7.8792, 7.8792, 75.25, 7.2292, 7.75, 69.3, 55.4417, 82.1708, 7.25, 227.525, 15.7417, 52.0, 13.0, 12.0, 120.0, 7.7958, 113.275, 16.7, 12.65, 7.925, 18.75, 90.0, 7.925, 32.5, 13.0, 26.0, 26.0, 8.05, 26.55, 16.1, 26.0, 120.0, 18.75, 26.25, 13.0, 8.1125, 81.8583, 19.5, 26.55, 19.2583, 30.5, 89.1042, 7.8958, 51.8625, 10.5, 26.55, 19.2583, 27.75, 13.7917, 12.2875, 9.5875, 91.0792, 90.0, 15.9, 78.2667, 86.5, 26.0, 26.55, 56.4958, 7.75, 26.2875, 59.4, 10.5, 26.0, 93.5, 57.9792, 10.5, 26.0, 22.3583, 26.25, 106.425, 49.5, 71.0, 26.0, 26.0, 13.8625, 36.75, 110.8833, 7.225, 7.775, 39.6, 79.65, 17.4, 7.8542, 10.5, 51.4792, 26.3875, 7.75, 13.0, 55.9, 7.925, 30.0, 110.8833, 79.65, 79.2, 78.2667, 33.0, 56.9292, 27.0, 26.55, 30.5, 41.5792, 153.4625, 15.5, 65.0, 39.0, 52.5542, 15.7417, 77.9583, 30.0, 30.5, 13.0, 69.3, 56.4958, 19.2583, 76.7292, 35.5, 7.55, 23.0, 7.8292, 133.65, 7.925, 52.0, 39.0, 13.0, 9.8417, 512.3292, 76.7292, 211.3375, 57.0, 13.4167, 56.4958, 7.7333, 227.525, 26.2875, 13.5, 26.2875, 151.55, 15.2458, 49.5042, 52.0, 227.525, 10.5, 33.0, 53.1, 21.0, 7.7375, 211.3375, 512.3292, 30.0, 262.375, 7.925, 13.0, 23.0, 12.475, 65.0, 14.5, 86.5, 7.2292, 120.0, 77.9583, 23.0, 12.475, 211.3375, 7.2292, 57.0, 7.4958, 20.575, 25.9292, 8.6833, 26.25, 120.0, 8.5167, 6.975, 53.1, 93.5, 8.6625, 12.475, 37.0042, 7.75, 80.0, 14.4542, 18.75, 83.1583, 56.4958, 29.7, 31.0, 89.1042, 39.4, 9.35, 164.8667, 26.55, 19.2583, 25.9292, 13.0, 13.8583, 11.1333, 52.5542, 24.0, 7.225, 83.1583, 26.0, 30.0, 30.0], \"type\": \"box\", \"name\": \"survived\"}], {\"xaxis\": {\"title\": \"Fare\"}, \"title\": \"Survival by Fare\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fare paid by those who passed away\n",
    "fares_deceased = train[\"Fare\"][train[\"Survived\"] == 0]\n",
    "\n",
    "#Fare paid by survivors\n",
    "fares_survived = train[\"Fare\"][train[\"Survived\"] == 1]\n",
    "\n",
    "#Survival by fare - Boxplot\n",
    "trace0 = go.Box(x = fares_deceased, name = \"deceased\")\n",
    "trace1 = go.Box(x = fares_survived, name = \"survived\")\n",
    "fare_by_survival_data = [trace0, trace1]\n",
    "layout = go.Layout(xaxis = dict(title = 'Fare'),title = \"Survival by Fare\")\n",
    "fig4 = go.Figure(data=fare_by_survival_data, layout=layout)\n",
    "iplot(fig4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fare distribution for those who survived is shifted more towards the right. Most survivors definitely paid higher than non-survivors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does Port of embarkation play a role?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will handle missing values with 'Embarked' column in the later section - Clean and format the data. For now, missing values have been excluded from the plot, to examine the data without any bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"e3cd80b6-7101-43e0-aaff-8b0ed59adfe1\" style=\"height: 400px; width: 400px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"e3cd80b6-7101-43e0-aaff-8b0ed59adfe1\", [{\"y\": [0.33695652173913043, 0.5535714285714286, 0.38961038961038963], \"x\": [\"S\", \"C\", \"Q\"], \"type\": \"bar\"}], {\"height\": 400, \"width\": 400, \"autosize\": false, \"yaxis\": {\"title\": \"Survival Rates\"}, \"title\": \"Survival by Embarked\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized Pclass survival\n",
    "S = train[\"Survived\"][train[\"Embarked\"] == \"S\"].value_counts(normalize = True)\n",
    "C = train[\"Survived\"][train[\"Embarked\"] == \"C\"].value_counts(normalize = True)\n",
    "Q = train[\"Survived\"][train[\"Embarked\"] == \"Q\"].value_counts(normalize = True)\n",
    "\n",
    "# Survival by Embarked - Boxplot\n",
    "x0 = ['S', 'C', 'Q']\n",
    "y0 = [S[1], C[1], Q[1]]\n",
    "plotly_barplot(x0, y0, ylab = 'Survival Rates', ptitle = 'Survival by Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple variable (2d) explorations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now explore multiple combination of variables to see how well they correlate with survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does survival rate varied by Class and Gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"577e3055-3c07-482f-8feb-a5c4879a82e9\" style=\"height: 400px; width: 500px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"577e3055-3c07-482f-8feb-a5c4879a82e9\", [{\"y\": [0.36885245901639346, 0.1574074074074074, 0.13544668587896252], \"x\": [\"Pclass 1\", \"Pclass 2\", \"Pclass 3\"], \"type\": \"bar\", \"name\": \"male\"}, {\"y\": [0.9680851063829787, 0.9210526315789473, 0.5], \"x\": [\"Pclass 1\", \"Pclass 2\", \"Pclass 3\"], \"type\": \"bar\", \"name\": \"female\"}], {\"autosize\": false, \"yaxis\": {\"title\": \"Survival Rates\"}, \"title\": \"Survival by Class and Gender\", \"height\": 400, \"barmode\": \"group\", \"width\": 500}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalized Pclass survival by gender\n",
    "Pclass1_male = train[\"Survived\"][(train[\"Pclass\"] == 1) & (train[\"Sex\"] == \"male\")].value_counts(normalize = True)\n",
    "Pclass2_male = train[\"Survived\"][(train[\"Pclass\"] == 2) & (train[\"Sex\"] == \"male\")].value_counts(normalize = True)\n",
    "Pclass3_male = train[\"Survived\"][(train[\"Pclass\"] == 3) & (train[\"Sex\"] == \"male\")].value_counts(normalize = True)\n",
    "\n",
    "Pclass1_female = train[\"Survived\"][(train[\"Pclass\"] == 1) & (train[\"Sex\"] == \"female\")].value_counts(normalize = True)\n",
    "Pclass2_female = train[\"Survived\"][(train[\"Pclass\"] == 2) & (train[\"Sex\"] == \"female\")].value_counts(normalize = True)\n",
    "Pclass3_female = train[\"Survived\"][(train[\"Pclass\"] == 3) & (train[\"Sex\"] == \"female\")].value_counts(normalize = True)\n",
    "\n",
    "# Survival by Class and Gender- Grouped Barplot\n",
    "trace0 = go.Bar(\n",
    "    x=['Pclass 1', 'Pclass 2', 'Pclass 3'],\n",
    "    y=[Pclass1_male[1], Pclass2_male[1], Pclass3_male[1]],\n",
    "    name='male'\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=['Pclass 1', 'Pclass 2', 'Pclass 3'],\n",
    "    y=[Pclass1_female[1], Pclass2_female[1], Pclass3_female[1]],\n",
    "    name='female'\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(autosize = False, width = 500, height = 400,\n",
    "    barmode='group',yaxis = dict(title = 'Survival Rates'),title = 'Survival by Class and Gender')\n",
    "\n",
    "fig6 = go.Figure(data=data, layout=layout)\n",
    "iplot(fig6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each Pclass, females tended to survive over their male counterparts. For both males and females, people in higher fare class tickets had higher survival rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Was there chivalry at work - Women and Child first ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We saw that age influenced survival. It is logical to think that children were saved first. We created a new column with a categorical variable Child. Child will take a value 1 for ages < 10 and a value of 0 for ages >= 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the column Child and assign 1 to passengers under 10, 0 to those 10 or older and NaN if age is NaN\n",
    "def is_child(age):\n",
    "    \"\"\"Defines what age is considered a child\"\"\"\n",
    "    if age < 10:\n",
    "        return float(1)\n",
    "    elif age >= 10:\n",
    "        return float(0)\n",
    "    else:\n",
    "        return float('NaN')\n",
    "# apply the function to 'Age' column of the dataframe\n",
    "train['Child'] = train['Age'].apply(is_child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"16c8266a-fb5a-43b8-b84b-88e829265042\" style=\"height: 400px; width: 400px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"16c8266a-fb5a-43b8-b84b-88e829265042\", [{\"y\": [0.6129032258064516, 0.38650306748466257], \"x\": [\"children\", \"adult\"], \"type\": \"bar\"}], {\"height\": 400, \"width\": 400, \"autosize\": false, \"yaxis\": {\"title\": \"Survival Rates\"}, \"title\": \"Children vs Adults\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print normalized Survival Rates for passengers under 10\n",
    "children = train['Survived'][train['Child'] == 1].value_counts(normalize = True)\n",
    "\n",
    "# Print normalized Survival Rates for passengers 10 or older\n",
    "adult = train['Survived'][train['Child'] == 0].value_counts(normalize = True)\n",
    "\n",
    "# Plot survival of children vs adults\n",
    "x0=['children', 'adult']\n",
    "y0=[children[1], adult[1]]\n",
    "plotly_barplot(x0, y0, ylab = 'Survival Rates', ptitle = 'Children vs Adults')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"7193ef1e-90b5-400d-8df4-19c76f71f95a\" style=\"height: 400px; width: 500px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"7193ef1e-90b5-400d-8df4-19c76f71f95a\", [{\"y\": [0.59375, 0.6333333333333333], \"x\": [\"male\", \"female\"], \"type\": \"bar\", \"name\": \"child (<10)\"}, {\"y\": [0.17577197149643706, 0.7705627705627706], \"x\": [\"male\", \"female\"], \"type\": \"bar\", \"name\": \"adult\"}], {\"autosize\": false, \"yaxis\": {\"title\": \"Survival Rates\"}, \"title\": \"Women and Children First\", \"height\": 400, \"barmode\": \"group\", \"width\": 500}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalised survival by sex and age\n",
    "male_child = train[\"Survived\"][(train[\"Sex\"] == 'male') & (train[\"Child\"] == 1)].value_counts(normalize = True)\n",
    "male_adult = train[\"Survived\"][(train[\"Sex\"] == 'male') & (train[\"Child\"] == 0)].value_counts(normalize = True)\n",
    "\n",
    "female_child = train[\"Survived\"][(train[\"Sex\"] == 'female') & (train[\"Child\"] == 1)].value_counts(normalize = True)\n",
    "female_adult = train[\"Survived\"][(train[\"Sex\"] == 'female') & (train[\"Child\"] == 0)].value_counts(normalize = True)\n",
    "\n",
    "trace0 = go.Bar(\n",
    "    x=['male', 'female'],\n",
    "    y=[male_child[1], female_child[1]],\n",
    "    name='child (<10)'\n",
    ")\n",
    "trace1 = go.Bar(\n",
    "    x=['male', 'female'],\n",
    "    y=[male_adult[1], female_adult[1]],\n",
    "    name='adult'\n",
    ")\n",
    "\n",
    "data = [trace0, trace1]\n",
    "layout = go.Layout(autosize = False, width = 500, height = 400,\n",
    "    barmode='group',yaxis = dict(title = 'Survival Rates'),title = 'Women and Children First')\n",
    "\n",
    "fig8 = go.Figure(data=data, layout=layout)\n",
    "iplot(fig8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was chivalry at work - women and children first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and format the train data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have been examining, the effect of one or two variable on survival. Machine learning algorithms automate this task by using multiple features to output a classification model or classifier. The use of classifier will be more exhaustive and more precise than our manual exploration above. Before we move on to use classification algorithms, we will have to clean the data so as to take maximum advantage of all the relevant features.\n",
    "\n",
    "The data isn't perfectly clean as we saw with train.describe() earlier. There are some missing values. Also not all columns were shown with .describe(). Only numeric columns were shown.\n",
    "\n",
    "We don't want to remove rows with **missing data**, as more data help us train our algorithm better. We also don't want to get rid of **non-numeric** columns. Non-numeric like 'Sex', as we saw were very important in predicting survival."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Age column has missing values NaN. The count for the column is 714, whereas other columns have a count of 891.\n",
    "We will impute the missing values in Age column with median of the column. Median age before imputation is 28. It lies right in the peak of distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"17796444-a5fd-45b2-a44e-2aa8e2ba6d17\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"17796444-a5fd-45b2-a44e-2aa8e2ba6d17\", [{\"showlegend\": true, \"legendgroup\": \"Before imputation\", \"name\": \"Before imputation\", \"yaxis\": \"y1\", \"y\": [0.005709426317874255, 0.0058423643723119765, 0.005971216759302968, 0.006095672425124257, 0.006215439174474744, 0.0063302455193083255, 0.006439842391322171, 0.006544004704096003, 0.006642532752605716, 0.006735253439717, 0.006822021321273902, 0.006902719463504153, 0.006977260108635806, 0.007045585146825746, 0.007107666394706488, 0.007163505683029738, 0.007213134757990633, 0.007256615002823096, 0.0072940369881342, 0.007325519861165342, 0.007351210585704817, 0.007371283045707448, 0.007385937026783316, 0.007395397090583747, 0.007399911357727826, 0.007399750215269523, 0.007395204964801832, 0.007386586427131973, 0.0073742235190471335, 0.007358461817034145, 0.007339662121933588, 0.007318199037417916, 0.007294459573906215, 0.0072688417880906195, 0.0072417534666789005, 0.007213610861284595, 0.0071848374796517865, 0.0071558629366191, 0.007127121866439921, 0.007099052896316365, 0.007072097679305546, 0.007046699983149649, 0.007023304830095236, 0.007002357681429625, 0.006984303659297252, 0.006969586797387705, 0.00695864931132756, 0.006951930879073725, 0.006949867921306707, 0.006952892871763361, 0.006961433427631752, 0.006975911770552408, 0.006996743749423444, 0.007024338017080188, 0.007059095113997906, 0.007101406493430138, 0.007151653483822744, 0.007210206185910149, 0.007277422303577962, 0.007353645909335514, 0.007439206147052254, 0.007534415876441251, 0.007639570265588985, 0.007754945339601233, 0.007880796495128246, 0.008017356992118536, 0.008164836435600646, 0.00832341926157958, 0.008493263242235411, 0.008674498026504556, 0.008867223732791817, 0.009071509610989188, 0.00928739279115515, 0.009514877136129226, 0.009753932215018577, 0.01000449241389764, 0.010266456199214334, 0.010539685548306166, 0.010824005560110402, 0.011119204257620917, 0.011425032591920613, 0.0117412046557257, 0.012067398112341789, 0.012403254843780439, 0.012748381819547247, 0.01310235218532048, 0.01346470656842385, 0.013834954594690725, 0.014212576609051716, 0.014597025589984169, 0.014987729245871311, 0.01538409227935828, 0.015785498803989512, 0.01619131489579012, 0.016600891261034634, 0.017013566000248014, 0.017428667447520724, 0.01784551706350302, 0.018263432359981457, 0.01868172983373561, 0.019099727887426463, 0.019516749715574065, 0.019932126134234777, 0.020345198333776016, 0.020755320535153703, 0.02116186253130836, 0.02156421209668879, 0.02196177724946537, 0.02235398835268369, 0.02274030004240765, 0.02312019297278215, 0.023493175369881995, 0.023858784388177196, 0.02421658726540987, 0.024566182273616236, 0.024907199465915447, 0.025239301220501213, 0.025562182584990743, 0.025875571425891166, 0.026179228389418198, 0.026472946681233844, 0.026756551673848585, 0.02702990035145088, 0.027292880602780494, 0.027545410373349677, 0.027787436688840574, 0.028018934561872752, 0.028239905794548652, 0.02845037768925721, 0.028650401680157634, 0.02884005189759004, 0.029019423677381445, 0.029188632026649418, 0.029347810057267377, 0.02949710739766028, 0.029636688593062503, 0.029766731503805304, 0.029887425710623205, 0.029998970935387885, 0.030101575485106093, 0.030195454726462415, 0.03028082959765576, 0.03035792516377391, 0.03042696922147717, 0.030488190958319596, 0.03054181967162407, 0.030588083551442703, 0.030627208531771918, 0.030659417213847302, 0.030684927865009905, 0.030703953496306544, 0.0307167010216541, 0.030723370501055048, 0.03072415446999125, 0.03071923735673939, 0.030708794988939275, 0.03069299419030118, 0.030671992467858955, 0.030645937789659447, 0.030614968452228147, 0.030579213036567847, 0.030538790450835625, 0.03049381005721092, 0.03044437187981977, 0.030390566889928895, 0.03033247736397632, 0.030270177309375475, 0.030203732952428695, 0.03013320328212533, 0.030058640643092546, 0.029980091370523952, 0.02989759645954432, 0.02981119226118685, 0.029720911196972198, 0.029626782483991275, 0.029528832862412865, 0.02942708731746371, 0.0293215697881646, 0.029212303855448384, 0.029099313402730802, 0.028982623242546166, 0.028862259703488692, 0.028738251172405405, 0.028610628587556218, 0.0284794258792772, 0.028344680355537995, 0.02820643303065982, 0.028064728896338015, 0.027919617134978352, 0.027771151276191567, 0.027619389298081765, 0.027464393675696426, 0.027306231379666642, 0.027144973828644135, 0.026980696799628185, 0.02681348030066341, 0.02664340841067407, 0.026470569091379903, 0.026295053976312658, 0.026116958141924197, 0.02593637986565073, 0.02575342037558093, 0.02556818359607651, 0.02538077589332342, 0.02519130582436119, 0.024999883892660245, 0.024806622312805934, 0.02461163478631614, 0.024415036290081554, 0.024216942878386258, 0.024017471498954224, 0.02381673982298548, 0.023614866088705107, 0.023411968957556414, 0.0232081673818345, 0.023003580482282734, 0.022798327433965492, 0.02259252735858785, 0.022386299221355932, 0.022179761730458082, 0.02197303323729412, 0.02176623163568064, 0.02155947425841055, 0.021352877769735417, 0.02114655805256276, 0.020940630089408194, 0.020735207836405693, 0.02053040408994919, 0.0203263303458075, 0.020123096650813233, 0.01992081144746967, 0.01971958141203855, 0.01951951128686516, 0.01932070370785638, 0.01912325902815451, 0.01892727513913939, 0.018732847289945606, 0.01854006790670074, 0.01834902641267618, 0.01815980905049763, 0.017972498707491798, 0.017787174745152658, 0.01760391283360108, 0.017422784791789863, 0.017243858434078378, 0.01706719742367183, 0.01689286113329537, 0.01672090451335699, 0.016551377967750164, 0.01638432723736063, 0.01621979329127512, 0.0160578122256445, 0.015898415170131915, 0.01574162820187807, 0.015587472266940626, 0.015435963109211633, 0.015287111206884687, 0.015140921716628678, 0.014997394425725872, 0.014856523712543934, 0.014718298515831911, 0.014582702313453717, 0.014449713111296503, 0.014319303443210646, 0.01419144038294875, 0.014066085569169834, 0.013943195244657676, 0.013822720310966019, 0.013704606399745337, 0.013588793962023605, 0.013475218376705258, 0.013363810079516654, 0.013254494713562662, 0.01314719330256625, 0.013041822447742308, 0.012938294549108307, 0.012836518051859633, 0.012736397718237478, 0.012637834925094604, 0.012540727987121197, 0.01244497250543207, 0.012350461740940996, 0.012257087011660738, 0.012164738112772282, 0.012073303758007277, 0.011982672040587741, 0.011892730911670162, 0.011803368673951958, 0.011714474487819765, 0.011625938887156382, 0.01153765430167903, 0.011449515582461062, 0.011361420527094521, 0.01127327040078723, 0.011184970449556627, 0.011096430401588338, 0.011007564952771177, 0.010918294232405727, 0.01082854424511116, 0.010738247285027171, 0.010647342318524192, 0.01055577533179663, 0.010463499639919698, 0.010370476154199433, 0.010276673604936316, 0.010182068717052555, 0.010086646336399307, 0.009990399504958435, 0.009893329483580364, 0.009795445721349936, 0.009696765771141001, 0.009597315151401888, 0.009497127154702656, 0.009396242604063692, 0.009294709558569415, 0.009192582970242304, 0.009089924294606838, 0.008986801057802762, 0.008883286383508165, 0.008779458483298442, 0.008675400114394383, 0.008571198009035328, 0.008466942279950285, 0.008362725806586266, 0.008258643606889162, 0.008154792199515122, 0.0080512689613812, 0.00794817148544223, 0.00784559694350872, 0.007743641458799689, 0.007642399492758024, 0.0075419632504472285, 0.007442422108601864, 0.007343862070123574, 0.00724636524850572, 0.007150009385336967, 0.007054867403683319, 0.006961006999784428, 0.006868490275128074, 0.006777373410593054, 0.006687706383978165, 0.006599532731870287, 0.0065128893564494585, 0.006427806377489252, 0.006344307029487494, 0.006262407603560045, 0.006182117433448983, 0.006103438924739291, 0.006026367626143995, 0.005950892341508792, 0.005876995281001324, 0.005804652249788565, 0.005733832872365442, 0.005664500850578841, 0.005596614253290376, 0.005530125835538207, 0.005464983384989146, 0.005401130093416672, 0.005338504950894686, 0.005277043160359872, 0.0052166765701649525, 0.005157334122218931, 0.005098942313287899, 0.005041425667008675, 0.004984707214147917, 0.004928708978619197, 0.004873352466751239, 0.004818559157280462, 0.004764250989522126, 0.004710350847155986, 0.004656783035046823, 0.0046034737465074915, 0.004550351518405035, 0.004497347671509399, 0.004444396733492498, 0.004391436842003585, 0.004338410125278285, 0.00428526305778416, 0.004231946788468476, 0.004178417439254535, 0.004124636371534667, 0.004070570418530815, 0.004016192081540291, 0.003961479688254407, 0.003906417511533136, 0.00385099584723879, 0.0037952110499769745, 0.0037390655258621288, 0.003682567681717425, 0.0036257318304330557, 0.003568578052540503, 0.003511132014411721, 0.0034534247438572137, 0.003395492364273549, 0.003337375788873945, 0.0032791203769222833, 0.0032207755542754055, 0.0031623944009174353, 0.0031040332085367412, 0.003045751011547275, 0.00298760909528474, 0.0029296704854105985, 0.002871999422826712, 0.0028146608286370974, 0.0027577197638844696, 0.002701240888935494, 0.0026452879274845476, 0.0025899231401891576, 0.0025352068129379838, 0.0024811967646824642, 0.0024279478796349727, 0.0023755116684490885, 0.0023239358627521007, 0.0022732640470974636, 0.0022235353320480306, 0.0021747840716928248, 0.0021270396284449357, 0.0020803261874709276, 0.0020346626225686937, 0.0019900624147474316, 0.0019465336241775435, 0.0019040789155774704, 0.0018626956364964388, 0.0018223759473458944, 0.0017831070014354686, 0.0017448711726911269, 0.0017076463281810112, 0.0016714061420573987, 0.0016361204470476721, 0.001601755619201169, 0.0015682749912276368, 0.0015356392894530987, 0.0015038070891738775, 0.0014727352830136429, 0.0014423795567833641, 0.001412694867312089, 0.001383635916756876, 0.0013551576180128072, 0.0013272155460260617, 0.0012997663700620185, 0.0012727682622914675, 0.0012461812784266288, 0.0012199677065585287, 0.0011940923808118006, 0.0011685229569347792, 0.0011432301474740979, 0.0011181879147357323, 0.0010933736203002197, 0.0010687681304303344, 0.0010443558772764633, 0.0010201248763403556, 0.000996066701194105, 0.0009721764169610305, 0.0009484524745419183, 0.0009248965680081102, 0.0009015134579767547, 0.0008783107641293507, 0.0008552987303284906, 0.0008324899660274645, 0.0008098991678509561, 0.0007875428253522473, 0.0007654389150226984, 0.0007436065866442772, 0.000722065846036822, 0.0007008372381615131, 0.0006799415344032929, 0.000659399427671805, 0.0006392312387367701, 0.0006194566369542175, 0.0006000943782495398, 0.0005811620629070013, 0.0005626759153783921, 0.0005446505879712146, 0.0005270989899144355, 0.000510032142932524, 0.0004934590640912722, 0.0004773866763164523, 0.00046181974663321395, 0.00044676085183437185, 0.0004322103709631557, 0.00041816650369396483, 0.0004046253134161215, 0.0003915807935730734, 0.00037902495558502327, 0.00036694793648817705, 0.0003553381242598823, 0.00034418229866661055, 0.00033346578537138004, 0.00032317262096861565, 0.0003132857265773398, 0.0003037870876168966, 0.00029465793741216984, 0.00028587894232587444, 0.0002774303861922629, 0.0002692923519274876, 0.00026144489831468154, 0.00025386823010417034, 0.0002465428597285565, 0.00023944975910608526, 0.00023257050019095916], \"mode\": \"lines\", \"xaxis\": \"x1\", \"marker\": {\"color\": \"#333F44\"}, \"x\": [0.42, 0.57916, 0.73832, 0.89748, 1.05664, 1.2158, 1.37496, 1.53412, 1.69328, 1.85244, 2.0116, 2.17076, 2.32992, 2.48908, 2.64824, 2.8074, 2.96656, 3.12572, 3.2848800000000002, 3.4440399999999998, 3.6031999999999997, 3.76236, 3.92152, 4.08068, 4.23984, 4.399, 4.55816, 4.71732, 4.87648, 5.03564, 5.1948, 5.35396, 5.51312, 5.67228, 5.83144, 5.9906, 6.149760000000001, 6.30892, 6.46808, 6.62724, 6.7863999999999995, 6.9455599999999995, 7.10472, 7.26388, 7.42304, 7.582199999999999, 7.741359999999999, 7.900519999999999, 8.05968, 8.21884, 8.378, 8.53716, 8.69632, 8.85548, 9.01464, 9.1738, 9.33296, 9.492119999999998, 9.65128, 9.81044, 9.9696, 10.12876, 10.28792, 10.44708, 10.60624, 10.7654, 10.92456, 11.08372, 11.24288, 11.40204, 11.5612, 11.720360000000001, 11.879520000000001, 12.03868, 12.19784, 12.357, 12.51616, 12.67532, 12.83448, 12.99364, 13.1528, 13.31196, 13.471119999999999, 13.630279999999999, 13.78944, 13.9486, 14.10776, 14.26692, 14.42608, 14.585239999999999, 14.744399999999999, 14.903559999999999, 15.062719999999999, 15.221879999999999, 15.381039999999999, 15.540199999999999, 15.69936, 15.85852, 16.017680000000002, 16.176840000000002, 16.336000000000002, 16.495160000000002, 16.654320000000002, 16.813480000000002, 16.972640000000002, 17.131800000000002, 17.290960000000002, 17.450120000000002, 17.609280000000002, 17.768440000000002, 17.9276, 18.08676, 18.24592, 18.405079999999998, 18.564239999999998, 18.723399999999998, 18.88256, 19.04172, 19.20088, 19.36004, 19.5192, 19.67836, 19.83752, 19.99668, 20.15584, 20.315, 20.47416, 20.63332, 20.79248, 20.95164, 21.1108, 21.26996, 21.42912, 21.58828, 21.74744, 21.9066, 22.06576, 22.22492, 22.38408, 22.54324, 22.7024, 22.861560000000004, 23.020720000000004, 23.179880000000004, 23.339040000000004, 23.498200000000004, 23.65736, 23.81652, 23.97568, 24.13484, 24.294, 24.45316, 24.61232, 24.77148, 24.93064, 25.0898, 25.24896, 25.40812, 25.56728, 25.72644, 25.8856, 26.04476, 26.20392, 26.36308, 26.52224, 26.6814, 26.84056, 26.999720000000003, 27.158880000000003, 27.318040000000003, 27.477200000000003, 27.636360000000003, 27.795520000000003, 27.954680000000003, 28.113840000000003, 28.273000000000003, 28.432160000000003, 28.591320000000003, 28.75048, 28.90964, 29.0688, 29.22796, 29.38712, 29.54628, 29.70544, 29.8646, 30.02376, 30.18292, 30.34208, 30.50124, 30.6604, 30.81956, 30.978720000000003, 31.137880000000003, 31.297040000000003, 31.456200000000003, 31.615360000000003, 31.774520000000003, 31.933680000000003, 32.09284, 32.252, 32.41116, 32.57032, 32.72948, 32.88864, 33.0478, 33.20696, 33.36612, 33.52528, 33.68444, 33.8436, 34.00276, 34.16192, 34.32108, 34.48024, 34.6394, 34.79856, 34.95772, 35.11688, 35.27604, 35.4352, 35.59436, 35.75352, 35.91268, 36.07184, 36.231, 36.390159999999995, 36.54932, 36.708479999999994, 36.86764, 37.026799999999994, 37.18596, 37.34512, 37.50428, 37.66344, 37.8226, 37.98176, 38.14092, 38.30008, 38.45924, 38.6184, 38.77756, 38.93672, 39.09588, 39.25504, 39.4142, 39.57336, 39.73252, 39.89168, 40.05084, 40.21, 40.36916, 40.52832, 40.68748, 40.84664, 41.0058, 41.16496, 41.32412000000001, 41.48328, 41.64244, 41.8016, 41.96076, 42.11992, 42.27908, 42.43824, 42.5974, 42.75656, 42.91572, 43.07488, 43.23404, 43.3932, 43.55236, 43.71152, 43.87068, 44.02984, 44.189, 44.34816, 44.50732, 44.66648, 44.82564, 44.9848, 45.14396, 45.30312000000001, 45.46228, 45.62144000000001, 45.7806, 45.93976000000001, 46.09892, 46.25808000000001, 46.41724, 46.57640000000001, 46.73556, 46.89472, 47.05388, 47.21304, 47.3722, 47.53136, 47.69052, 47.84968, 48.00884, 48.168, 48.32716, 48.48632, 48.64548, 48.80464, 48.9638, 49.12296, 49.28212, 49.44128, 49.600440000000006, 49.7596, 49.918760000000006, 50.07792, 50.237080000000006, 50.39624, 50.555400000000006, 50.71456, 50.873720000000006, 51.03288, 51.192040000000006, 51.3512, 51.510360000000006, 51.66952, 51.82868, 51.98784, 52.147, 52.30616, 52.46532, 52.62448, 52.78364, 52.9428, 53.10196, 53.26112, 53.42028, 53.579440000000005, 53.7386, 53.897760000000005, 54.05692, 54.216080000000005, 54.37524, 54.534400000000005, 54.69356, 54.852720000000005, 55.01188, 55.171040000000005, 55.3302, 55.489360000000005, 55.64852, 55.807680000000005, 55.96684, 56.126000000000005, 56.28516, 56.444320000000005, 56.60348, 56.762640000000005, 56.9218, 57.08096, 57.24012, 57.39928, 57.558440000000004, 57.7176, 57.876760000000004, 58.03592, 58.195080000000004, 58.35424, 58.513400000000004, 58.67256, 58.831720000000004, 58.99088, 59.150040000000004, 59.3092, 59.468360000000004, 59.62752, 59.786680000000004, 59.94584, 60.105000000000004, 60.26416, 60.423320000000004, 60.58248, 60.741640000000004, 60.9008, 61.059960000000004, 61.21912, 61.378280000000004, 61.537440000000004, 61.696600000000004, 61.855760000000004, 62.01492, 62.174080000000004, 62.333239999999996, 62.4924, 62.651559999999996, 62.81072, 62.969879999999996, 63.12904, 63.288199999999996, 63.44736, 63.606519999999996, 63.76568, 63.924839999999996, 64.084, 64.24315999999999, 64.40232, 64.56148, 64.72064, 64.8798, 65.03896, 65.19812, 65.35728, 65.51644, 65.6756, 65.83476, 65.99392, 66.15308, 66.31224, 66.4714, 66.63056, 66.78972, 66.94888, 67.10803999999999, 67.2672, 67.42636, 67.58552, 67.74467999999999, 67.90384, 68.063, 68.22216, 68.38131999999999, 68.54048, 68.69964, 68.8588, 69.01795999999999, 69.17712, 69.33628, 69.49544, 69.65459999999999, 69.81376, 69.97292, 70.13208, 70.29124, 70.4504, 70.60956, 70.76872, 70.92788, 71.08704, 71.2462, 71.40536, 71.56452, 71.72368, 71.88284, 72.042, 72.20116, 72.36031999999999, 72.51948, 72.67864, 72.8378, 72.99695999999999, 73.15612, 73.31528, 73.47444, 73.63359999999999, 73.79276, 73.95192, 74.11108, 74.27024, 74.4294, 74.58856, 74.74772, 74.90688, 75.06604, 75.2252, 75.38436, 75.54352, 75.70268, 75.86184, 76.021, 76.18016, 76.33932, 76.49848, 76.65764, 76.8168, 76.97596, 77.13512, 77.29428, 77.45344, 77.61259999999999, 77.77176, 77.93092, 78.09008, 78.24924, 78.4084, 78.56756, 78.72672, 78.88588, 79.04504, 79.2042, 79.36336, 79.52252, 79.68168, 79.84084], \"type\": \"scatter\"}, {\"showlegend\": true, \"legendgroup\": \"After imputation\", \"name\": \"After imputation\", \"yaxis\": \"y1\", \"y\": [0.0048600335125109076, 0.004994420268695759, 0.005124089364549739, 0.0052486008661914085, 0.005367542802766918, 0.005480534515514374, 0.005587229710671348, 0.0056873191790065185, 0.005780533149444686, 0.0058666432495037705, 0.005945464050983699, 0.006016854185442055, 0.006080717020353519, 0.006137000893368016, 0.006185698908640941, 0.006226848305691791, 0.006260529417540126, 0.006286864240858416, 0.006306014646464347, 0.006318180263551785, 0.006323596075541561, 0.006322529769242058, 0.006315278882080617, 0.006302167794447867, 0.006283544615651619, 0.006259778012582845, 0.006231254029947371, 0.0061983729498223256, 0.006161546236380791, 0.006121193608930795, 0.006077740282988891, 0.006031614415020517, 0.005983244781806731, 0.005933058720227779, 0.005881480347684868, 0.005828929077515348, 0.005775818437701472, 0.005722555195039436, 0.005669538780835207, 0.0056171610082366855, 0.005565806065605098, 0.00551585076497393, 0.005467665019735676, 0.005421612521321627, 0.005378051580873199, 0.00533733609880975, 0.005299816622828749, 0.00526584145326815, 0.005235757753942154, 0.0052099126265400955, 0.005188654107449755, 0.005172332047412548, 0.005161298836706586, 0.0051559099415397274, 0.005156524220961753, 0.005163503997805145, 0.005177214861860952, 0.00519802518860567, 0.005226305362225976, 0.005262426697346159, 0.005306760059650274, 0.005359674191409362, 0.0054215337536760244, 0.005492697102499549, 0.005573513821853979, 0.005664322040974149, 0.005765445568382735, 0.005877190878994919, 0.005999843994245355, 0.006133667298143866, 0.006278896334490587, 0.006435736632138377, 0.006604360606160758, 0.006784904583059123, 0.006977465997725647, 0.007182100808780784, 0.007398821177148557, 0.007627593450350451, 0.007868336492029256, 0.008120920392704772, 0.008385165593767842, 0.008660842452296673, 0.008947671269494053, 0.009245322800462908, 0.009553419257730351, 0.00987153581546777, 0.010199202615807713, 0.010535907273096822, 0.01088109786641625, 0.011234186405311092, 0.01159455274845903, 0.01196154895003111, 0.012334504003803546, 0.012712728950711608, 0.013095522311529856, 0.013482175802745149, 0.013871980290478451, 0.014264231934519422, 0.014658238472166695, 0.01505332558960983, 0.015448843327033958, 0.015844172462453548, 0.0162387308184625, 0.01663197943559229, 0.017023428555765007, 0.017412643359378577, 0.017799249399832476, 0.018182937679762427, 0.018563469313874186, 0.018940679724029495, 0.019314482313130037, 0.01968487156536691, 0.020051925521565463, 0.020415807579683486, 0.020776767572054624, 0.021135142072763093, 0.02149135389065963, 0.021845910706064686, 0.022199402812248654, 0.02255249992643348, 0.02290594703943759, 0.023260559278298214, 0.023617215762363666, 0.023976852440556518, 0.024340453905856485, 0.02470904419261264, 0.025083676573112883, 0.02546542238193203, 0.025855358909926247, 0.026254556424278534, 0.026664064386619224, 0.02708489695778766, 0.027518017895058106, 0.02796432496536173, 0.02842463401588592, 0.02889966286106161, 0.029390015161956065, 0.029896164490033492, 0.03041843878166312, 0.030957005402159652, 0.0315118570480476, 0.03208279872316823, 0.03266943602774004, 0.033271164999122964, 0.03388716373845735, 0.03451638604825648, 0.03515755729221173, 0.03580917266980682, 0.03646949807481918, 0.0371365736785221, 0.037808220345613645, 0.038482048953944886, 0.03915547264847396, 0.03982572201613423, 0.04048986312218134, 0.04114481830088926, 0.041787389545091605, 0.04241428429097989, 0.04302214334777886, 0.043607570677456846, 0.04416716468851995, 0.04469755067118168, 0.04519541396973527, 0.04565753346263857, 0.04608081490240094, 0.0464623236564523, 0.046799316387240525, 0.04708927121514058, 0.04732991592148012, 0.04751925377101946, 0.04765558656330126, 0.047737534559954706, 0.0477640529796642, 0.04773444480329034, 0.04764836968760819, 0.04750584884622204, 0.04730726581924071, 0.047053363117995926, 0.046745234796153036, 0.04638431506268613, 0.04597236311407468, 0.045511444421486295, 0.0450039087624838, 0.04445236533488874, 0.04385965533193844, 0.04322882239203649, 0.042563081362638575, 0.04186578583574006, 0.04114039492183689, 0.040390439730104456, 0.03961949001505822, 0.038831121434482106, 0.03802888384046039, 0.037216270995599855, 0.03639669207078352, 0.035573445239964606, 0.03474969364257791, 0.03392844393615726, 0.033112527611773565, 0.03230458519401646, 0.03150705339647961, 0.030722155254071317, 0.02995189320588472, 0.029198045057662738, 0.02846216271181533, 0.027745573516108592, 0.0270493840500389, 0.026374486140894497, 0.025721564879824646, 0.025091108391987475, 0.02448341910401223, 0.023898626246457118, 0.023336699328429494, 0.022797462325730274, 0.022280608332377293, 0.021785714437678867, 0.021312256606644396, 0.02085962435987711, 0.020427135069620614, 0.020014047710745955, 0.019619575928603288, 0.019242900309274866, 0.018883179761342468, 0.018539561941353023, 0.018211192677311017, 0.017897224365381947, 0.01759682333425304, 0.01730917618902299, 0.01703349516190152, 0.016769022510271382, 0.016515034013741416, 0.01627084163068936, 0.016035795381505985, 0.015809284530390988, 0.015590738140247301, 0.015379625076129137, 0.015175453532005325, 0.01497777015350489, 0.014786158826028567, 0.014600239193357603, 0.014419664966886143, 0.014244122080057618, 0.014073326736699384, 0.013907023395908352, 0.013744982730111618, 0.01358699958705638, 0.013432890980897482, 0.013282494132349934, 0.013135664573135532, 0.012992274325732548, 0.012852210165767559, 0.012715371971282967, 0.012581671160565881, 0.012451029218213262, 0.012323376307599707, 0.012198649966862665, 0.01207679388487228, 0.011957756753351232, 0.011841491191293288, 0.011727952738036874, 0.011617098911723288, 0.011508888330352478, 0.011403279893193896, 0.011300232020871388, 0.011199701952983832, 0.011101645102618088, 0.011006014467536927, 0.010912760098167567, 0.01082182862276945, 0.010733162830321625, 0.010646701311743898, 0.010562378160060549, 0.0104801227300407, 0.010399859457718303, 0.010321507740020585, 0.010244981874529293, 0.010170191059176421, 0.010097039451445272, 0.01002542628641652, 0.009955246052772855, 0.00988638872565677, 0.009818740055064465, 0.00975218190825173, 0.009686592664420244, 0.009621847659739068, 0.00955781968052888, 0.009494379502188116, 0.009431396471164175, 0.009368739126962634, 0.009306275860839522, 0.00924387560743352, 0.009181408565167843, 0.00911874694078855, 0.009055765712914611, 0.008992343408964217, 0.008928362889305092, 0.008863712131968769, 0.008798285010787256, 0.008731982059374532, 0.008664711213004135, 0.00859638852014772, 0.008526938815256872, 0.008456296344308863, 0.00838440533471206, 0.008311220501389788, 0.008236707481241728, 0.008160843188722951, 0.008083616085983035, 0.008005026361865284, 0.007925086015070276, 0.007843818837923152, 0.00776126029843208, 0.007677457319663356, 0.007592467956859558, 0.00750636097416389, 0.007419215324253713, 0.007331119535599812, 0.007242171013421571, 0.00715247526167356, 0.0070621450345450055, 0.006971299426956705, 0.006880062914375268, 0.006788564352916116, 0.0066969359511586165, 0.006605312225342777, 0.006513828949651643, 0.006422622113110991, 0.006331826894264071, 0.006241576664217118, 0.006152002027917648, 0.006063229912643094, 0.005975382711666366, 0.0058885774899539375, 0.005802925257569587, 0.0057185303152323015, 0.00563548967523931, 0.0055538925597430795, 0.005473819977191855, 0.0053953443766304775, 0.005318529378534885, 0.005243429579936411, 0.005170090430797092, 0.0050985481779330325, 0.005028829872257827, 0.0049609534347322005, 0.004894927776159368, 0.004830752965850965, 0.004768420444198348, 0.004707913274305314, 0.004649206428058279, 0.00459226710231091, 0.004537055061226846, 0.00448352300123667, 0.004431616935507688, 0.004381276595278135, 0.004332435845856361, 0.004285023115513809, 0.004238961835896221, 0.004194170892928029, 0.004150565087482293, 0.0041080556053252875, 0.004066550496016979, 0.004025955160554066, 0.003986172847580537, 0.003947105157964778, 0.003908652557454792, 0.003870714896980537, 0.003833191939980131, 0.0037959838958930995, 0.0037589919586960494, 0.0037221188490633795, 0.0036852693584253976, 0.0036483508928776913, 0.0036112740145758976, 0.0035739529779373527, 0.0035363062576717, 0.0034982570653832364, 0.0034597338512336114, 0.0034206707869299693, 0.003381008226114448, 0.003340693138080661, 0.0032996795106339204, 0.0032579287178484623, 0.0032154098484585363, 0.0031720999906544784, 0.003127984469141284, 0.003083057030458837, 0.0030373199727614444, 0.0029907842165120928, 0.002943469312865703, 0.0028954033868969394, 0.0028466230132734786, 0.0027971730224848313, 0.0027471062363104894, 0.0026964831318470875, 0.0026453714341110124, 0.0025938456379856387, 0.0025419864610867486, 0.0024898802299676017, 0.0024376182029688274, 0.002385295833925936, 0.002333011981867421, 0.0022808680727537615, 0.0022289672202074483, 0.002177413313047825, 0.0021263100782554158, 0.002075760128727932, 0.0020258640058363254, 0.0019767192273245048, 0.0019284193515026469, 0.0018810530689446084, 0.0018347033329998126, 0.0017894465403566005, 0.0017453517726379437, 0.0017024801095654914, 0.001660884023591842, 0.0016206068650756775, 0.0015816824460660752, 0.0015441347295816667, 0.0015079776299323742, 0.00147321492815551, 0.0014398403050474937, 0.001407837492593759, 0.0013771805428629824, 0.001347834211669035, 0.0013197544525494348, 0.0012928890148965803, 0.001267178138442844, 0.001242555334775686, 0.0012189482451767943, 0.0011962795628685664, 0.0011744680067384734, 0.0011534293328181481, 0.0011330773692370569, 0.0011133250600618083, 0.0010940855033784622, 0.0010752729691769038, 0.001056803883049026, 0.0010385977624052436, 0.0010205780928314553, 0.0010026731333300013, 0.0009848166404889402, 0.0009669485030754793, 0.0009490152801204198, 0.0009309706372177271, 0.0009127756774723762, 0.0008943991652557519, 0.0008758176426369963, 0.0008570154400181463, 0.0008379845840801927, 0.0008187246076187297, 0.000799242267187475, 0.000779551175655387, 0.0007596713578023089, 0.000739628737917539, 0.0007194545690181241, 0.0006991848137666903, 0.0006788594874433762, 0.0006585219734188754, 0.0006382183214943614, 0.0006179965392318239, 0.0005979058860092973, 0.0005779961790168647, 0.0005583171197789162, 0.0005389176490654361, 0.0005198453372589945, 0.0005011458163941432, 0.00048286225920034687, 0.0004650349095759004, 0.0004477006680145212, 0.0004308927346128044, 0.00041464031141808585, 0.00039896836504309, 0.0003838974496847916, 0.000369443589947007, 0.0003556182221844237, 0.0003424281924634972, 0.00032987580867489607, 0.00031795894383371715, 0.0003066711871673105, 0.00029600203921524874, 0.0002859371468501886, 0.0002764585738702251, 0.0002675451026107258, 0.0002591725618744502, 0.00025131417638094743, 0.00024394093288785757, 0.00023702195813609804, 0.0002305249038163249, 0.00022441633384420083, 0.0002186621093653179, 0.0002132277670858478, 0.00020807888674055143, 0.0002031814437639813, 0.00019850214352155776, 0.00019400873378228473, 0.0001896702924713518, 0.00018545748812535446, 0.0001813428108814398, 0.00017730077225985792], \"mode\": \"lines\", \"xaxis\": \"x1\", \"marker\": {\"color\": \"#37AA9C\"}, \"x\": [0.42, 0.57916, 0.73832, 0.89748, 1.05664, 1.2158, 1.37496, 1.53412, 1.69328, 1.85244, 2.0116, 2.17076, 2.32992, 2.48908, 2.64824, 2.8074, 2.96656, 3.12572, 3.2848800000000002, 3.4440399999999998, 3.6031999999999997, 3.76236, 3.92152, 4.08068, 4.23984, 4.399, 4.55816, 4.71732, 4.87648, 5.03564, 5.1948, 5.35396, 5.51312, 5.67228, 5.83144, 5.9906, 6.149760000000001, 6.30892, 6.46808, 6.62724, 6.7863999999999995, 6.9455599999999995, 7.10472, 7.26388, 7.42304, 7.582199999999999, 7.741359999999999, 7.900519999999999, 8.05968, 8.21884, 8.378, 8.53716, 8.69632, 8.85548, 9.01464, 9.1738, 9.33296, 9.492119999999998, 9.65128, 9.81044, 9.9696, 10.12876, 10.28792, 10.44708, 10.60624, 10.7654, 10.92456, 11.08372, 11.24288, 11.40204, 11.5612, 11.720360000000001, 11.879520000000001, 12.03868, 12.19784, 12.357, 12.51616, 12.67532, 12.83448, 12.99364, 13.1528, 13.31196, 13.471119999999999, 13.630279999999999, 13.78944, 13.9486, 14.10776, 14.26692, 14.42608, 14.585239999999999, 14.744399999999999, 14.903559999999999, 15.062719999999999, 15.221879999999999, 15.381039999999999, 15.540199999999999, 15.69936, 15.85852, 16.017680000000002, 16.176840000000002, 16.336000000000002, 16.495160000000002, 16.654320000000002, 16.813480000000002, 16.972640000000002, 17.131800000000002, 17.290960000000002, 17.450120000000002, 17.609280000000002, 17.768440000000002, 17.9276, 18.08676, 18.24592, 18.405079999999998, 18.564239999999998, 18.723399999999998, 18.88256, 19.04172, 19.20088, 19.36004, 19.5192, 19.67836, 19.83752, 19.99668, 20.15584, 20.315, 20.47416, 20.63332, 20.79248, 20.95164, 21.1108, 21.26996, 21.42912, 21.58828, 21.74744, 21.9066, 22.06576, 22.22492, 22.38408, 22.54324, 22.7024, 22.861560000000004, 23.020720000000004, 23.179880000000004, 23.339040000000004, 23.498200000000004, 23.65736, 23.81652, 23.97568, 24.13484, 24.294, 24.45316, 24.61232, 24.77148, 24.93064, 25.0898, 25.24896, 25.40812, 25.56728, 25.72644, 25.8856, 26.04476, 26.20392, 26.36308, 26.52224, 26.6814, 26.84056, 26.999720000000003, 27.158880000000003, 27.318040000000003, 27.477200000000003, 27.636360000000003, 27.795520000000003, 27.954680000000003, 28.113840000000003, 28.273000000000003, 28.432160000000003, 28.591320000000003, 28.75048, 28.90964, 29.0688, 29.22796, 29.38712, 29.54628, 29.70544, 29.8646, 30.02376, 30.18292, 30.34208, 30.50124, 30.6604, 30.81956, 30.978720000000003, 31.137880000000003, 31.297040000000003, 31.456200000000003, 31.615360000000003, 31.774520000000003, 31.933680000000003, 32.09284, 32.252, 32.41116, 32.57032, 32.72948, 32.88864, 33.0478, 33.20696, 33.36612, 33.52528, 33.68444, 33.8436, 34.00276, 34.16192, 34.32108, 34.48024, 34.6394, 34.79856, 34.95772, 35.11688, 35.27604, 35.4352, 35.59436, 35.75352, 35.91268, 36.07184, 36.231, 36.390159999999995, 36.54932, 36.708479999999994, 36.86764, 37.026799999999994, 37.18596, 37.34512, 37.50428, 37.66344, 37.8226, 37.98176, 38.14092, 38.30008, 38.45924, 38.6184, 38.77756, 38.93672, 39.09588, 39.25504, 39.4142, 39.57336, 39.73252, 39.89168, 40.05084, 40.21, 40.36916, 40.52832, 40.68748, 40.84664, 41.0058, 41.16496, 41.32412000000001, 41.48328, 41.64244, 41.8016, 41.96076, 42.11992, 42.27908, 42.43824, 42.5974, 42.75656, 42.91572, 43.07488, 43.23404, 43.3932, 43.55236, 43.71152, 43.87068, 44.02984, 44.189, 44.34816, 44.50732, 44.66648, 44.82564, 44.9848, 45.14396, 45.30312000000001, 45.46228, 45.62144000000001, 45.7806, 45.93976000000001, 46.09892, 46.25808000000001, 46.41724, 46.57640000000001, 46.73556, 46.89472, 47.05388, 47.21304, 47.3722, 47.53136, 47.69052, 47.84968, 48.00884, 48.168, 48.32716, 48.48632, 48.64548, 48.80464, 48.9638, 49.12296, 49.28212, 49.44128, 49.600440000000006, 49.7596, 49.918760000000006, 50.07792, 50.237080000000006, 50.39624, 50.555400000000006, 50.71456, 50.873720000000006, 51.03288, 51.192040000000006, 51.3512, 51.510360000000006, 51.66952, 51.82868, 51.98784, 52.147, 52.30616, 52.46532, 52.62448, 52.78364, 52.9428, 53.10196, 53.26112, 53.42028, 53.579440000000005, 53.7386, 53.897760000000005, 54.05692, 54.216080000000005, 54.37524, 54.534400000000005, 54.69356, 54.852720000000005, 55.01188, 55.171040000000005, 55.3302, 55.489360000000005, 55.64852, 55.807680000000005, 55.96684, 56.126000000000005, 56.28516, 56.444320000000005, 56.60348, 56.762640000000005, 56.9218, 57.08096, 57.24012, 57.39928, 57.558440000000004, 57.7176, 57.876760000000004, 58.03592, 58.195080000000004, 58.35424, 58.513400000000004, 58.67256, 58.831720000000004, 58.99088, 59.150040000000004, 59.3092, 59.468360000000004, 59.62752, 59.786680000000004, 59.94584, 60.105000000000004, 60.26416, 60.423320000000004, 60.58248, 60.741640000000004, 60.9008, 61.059960000000004, 61.21912, 61.378280000000004, 61.537440000000004, 61.696600000000004, 61.855760000000004, 62.01492, 62.174080000000004, 62.333239999999996, 62.4924, 62.651559999999996, 62.81072, 62.969879999999996, 63.12904, 63.288199999999996, 63.44736, 63.606519999999996, 63.76568, 63.924839999999996, 64.084, 64.24315999999999, 64.40232, 64.56148, 64.72064, 64.8798, 65.03896, 65.19812, 65.35728, 65.51644, 65.6756, 65.83476, 65.99392, 66.15308, 66.31224, 66.4714, 66.63056, 66.78972, 66.94888, 67.10803999999999, 67.2672, 67.42636, 67.58552, 67.74467999999999, 67.90384, 68.063, 68.22216, 68.38131999999999, 68.54048, 68.69964, 68.8588, 69.01795999999999, 69.17712, 69.33628, 69.49544, 69.65459999999999, 69.81376, 69.97292, 70.13208, 70.29124, 70.4504, 70.60956, 70.76872, 70.92788, 71.08704, 71.2462, 71.40536, 71.56452, 71.72368, 71.88284, 72.042, 72.20116, 72.36031999999999, 72.51948, 72.67864, 72.8378, 72.99695999999999, 73.15612, 73.31528, 73.47444, 73.63359999999999, 73.79276, 73.95192, 74.11108, 74.27024, 74.4294, 74.58856, 74.74772, 74.90688, 75.06604, 75.2252, 75.38436, 75.54352, 75.70268, 75.86184, 76.021, 76.18016, 76.33932, 76.49848, 76.65764, 76.8168, 76.97596, 77.13512, 77.29428, 77.45344, 77.61259999999999, 77.77176, 77.93092, 78.09008, 78.24924, 78.4084, 78.56756, 78.72672, 78.88588, 79.04504, 79.2042, 79.36336, 79.52252, 79.68168, 79.84084], \"type\": \"scatter\"}, {\"showlegend\": false, \"legendgroup\": \"Before imputation\", \"name\": \"Before imputation\", \"yaxis\": \"y2\", \"text\": null, \"y\": [\"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\", \"Before imputation\"], \"mode\": \"markers\", \"xaxis\": \"x1\", \"marker\": {\"color\": \"#333F44\", \"symbol\": \"line-ns-open\"}, \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, 31.0, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, 19.0, 40.0, 66.0, 28.0, 42.0, 21.0, 18.0, 14.0, 40.0, 27.0, 3.0, 19.0, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, 0.83, 30.0, 22.0, 29.0, 28.0, 17.0, 33.0, 16.0, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, 71.0, 23.0, 34.0, 34.0, 28.0, 21.0, 33.0, 37.0, 28.0, 21.0, 38.0, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, 32.5, 32.5, 54.0, 12.0, 24.0, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, 51.0, 16.0, 30.0, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, 45.0, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, 50.0, 30.0, 36.0, 9.0, 1.0, 4.0, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, 42.0, 24.0, 28.0, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, 38.0, 22.0, 19.0, 20.5, 18.0, 35.0, 29.0, 59.0, 5.0, 24.0, 44.0, 8.0, 19.0, 33.0, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, 29.0, 62.0, 30.0, 41.0, 29.0, 30.0, 35.0, 50.0, 3.0, 52.0, 40.0, 36.0, 16.0, 25.0, 58.0, 35.0, 25.0, 41.0, 37.0, 63.0, 45.0, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, 23.5, 2.0, 50.0, 19.0, 0.92, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, 36.0, 61.0, 36.0, 31.0, 16.0, 45.5, 38.0, 16.0, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, 3.0, 42.0, 23.0, 15.0, 25.0, 28.0, 22.0, 38.0, 40.0, 29.0, 45.0, 35.0, 30.0, 60.0, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, 18.0, 1.0, 36.0, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, 33.0, 44.0, 34.0, 18.0, 30.0, 10.0, 21.0, 29.0, 28.0, 18.0, 28.0, 19.0, 32.0, 28.0, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, 30.0, 49.0, 29.0, 65.0, 50.0, 48.0, 34.0, 47.0, 48.0, 38.0, 56.0, 0.75, 38.0, 33.0, 23.0, 22.0, 34.0, 29.0, 22.0, 2.0, 9.0, 50.0, 63.0, 25.0, 35.0, 58.0, 30.0, 9.0, 21.0, 55.0, 71.0, 21.0, 54.0, 25.0, 24.0, 17.0, 21.0, 37.0, 16.0, 18.0, 33.0, 28.0, 26.0, 29.0, 36.0, 54.0, 24.0, 47.0, 34.0, 36.0, 32.0, 30.0, 22.0, 44.0, 40.5, 50.0, 39.0, 23.0, 2.0, 17.0, 30.0, 7.0, 45.0, 30.0, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, 33.0, 8.0, 17.0, 27.0, 22.0, 22.0, 62.0, 48.0, 39.0, 36.0, 40.0, 28.0, 24.0, 19.0, 29.0, 32.0, 62.0, 53.0, 36.0, 16.0, 19.0, 34.0, 39.0, 32.0, 25.0, 39.0, 54.0, 36.0, 18.0, 47.0, 60.0, 22.0, 35.0, 52.0, 47.0, 37.0, 36.0, 49.0, 49.0, 24.0, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, 80.0, 51.0, 32.0, 9.0, 28.0, 32.0, 31.0, 41.0, 20.0, 24.0, 2.0, 0.75, 48.0, 19.0, 56.0, 23.0, 18.0, 21.0, 18.0, 24.0, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, 43.0, 40.0, 31.0, 70.0, 31.0, 18.0, 24.5, 18.0, 43.0, 36.0, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, 25.0, 60.0, 52.0, 44.0, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, 24.0, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, 25.0, 25.0, 29.0, 11.0, 23.0, 23.0, 28.5, 48.0, 35.0, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, 41.0, 20.0, 36.0, 16.0, 51.0, 30.5, 32.0, 24.0, 48.0, 57.0, 54.0, 18.0, 5.0, 43.0, 13.0, 17.0, 29.0, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, 16.0, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, 1.0, 62.0, 15.0, 0.83, 23.0, 18.0, 39.0, 21.0, 32.0, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, 35.0, 28.0, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, 41.0, 21.0, 48.0, 24.0, 42.0, 27.0, 31.0, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, 26.0, 32.0], \"type\": \"scatter\"}, {\"showlegend\": false, \"legendgroup\": \"After imputation\", \"name\": \"After imputation\", \"yaxis\": \"y2\", \"text\": null, \"y\": [\"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\", \"After imputation\"], \"mode\": \"markers\", \"xaxis\": \"x1\", \"marker\": {\"color\": \"#37AA9C\", \"symbol\": \"line-ns-open\"}, \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, 28.0, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, 28.0, 31.0, 28.0, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, 28.0, 19.0, 28.0, 28.0, 40.0, 28.0, 28.0, 66.0, 28.0, 42.0, 28.0, 21.0, 18.0, 14.0, 40.0, 27.0, 28.0, 3.0, 19.0, 28.0, 28.0, 28.0, 28.0, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, 28.0, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, 28.0, 28.0, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, 28.0, 28.0, 0.83, 30.0, 22.0, 29.0, 28.0, 28.0, 17.0, 33.0, 16.0, 28.0, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, 28.0, 71.0, 23.0, 34.0, 34.0, 28.0, 28.0, 21.0, 33.0, 37.0, 28.0, 21.0, 28.0, 38.0, 28.0, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, 28.0, 32.5, 32.5, 54.0, 12.0, 28.0, 24.0, 28.0, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, 28.0, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, 28.0, 51.0, 16.0, 30.0, 28.0, 28.0, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, 28.0, 45.0, 28.0, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, 28.0, 50.0, 30.0, 36.0, 28.0, 28.0, 9.0, 1.0, 4.0, 28.0, 28.0, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, 28.0, 42.0, 28.0, 24.0, 28.0, 28.0, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, 28.0, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, 28.0, 38.0, 22.0, 19.0, 20.5, 18.0, 28.0, 35.0, 29.0, 59.0, 5.0, 24.0, 28.0, 44.0, 8.0, 19.0, 33.0, 28.0, 28.0, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, 28.0, 29.0, 62.0, 30.0, 41.0, 29.0, 28.0, 30.0, 35.0, 50.0, 28.0, 3.0, 52.0, 40.0, 28.0, 36.0, 16.0, 25.0, 58.0, 35.0, 28.0, 25.0, 41.0, 37.0, 28.0, 63.0, 45.0, 28.0, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, 28.0, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, 28.0, 23.5, 2.0, 28.0, 50.0, 28.0, 28.0, 19.0, 28.0, 28.0, 0.92, 28.0, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, 28.0, 36.0, 61.0, 36.0, 31.0, 16.0, 28.0, 45.5, 38.0, 16.0, 28.0, 28.0, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, 28.0, 3.0, 42.0, 23.0, 28.0, 15.0, 25.0, 28.0, 28.0, 22.0, 38.0, 28.0, 28.0, 40.0, 29.0, 45.0, 35.0, 28.0, 30.0, 60.0, 28.0, 28.0, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, 28.0, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, 28.0, 18.0, 1.0, 36.0, 28.0, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, 28.0, 28.0, 28.0, 33.0, 28.0, 44.0, 28.0, 34.0, 18.0, 30.0, 10.0, 28.0, 21.0, 29.0, 28.0, 18.0, 28.0, 28.0, 19.0, 28.0, 32.0, 28.0, 28.0, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, 28.0, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, 28.0, 30.0, 49.0, 28.0, 29.0, 65.0, 28.0, 50.0, 28.0, 48.0, 34.0, 47.0, 48.0, 28.0, 38.0, 28.0, 56.0, 28.0, 0.75, 28.0, 38.0, 33.0, 23.0, 22.0, 28.0, 34.0, 29.0, 22.0, 2.0, 9.0, 28.0, 50.0, 63.0, 25.0, 28.0, 35.0, 58.0, 30.0, 9.0, 28.0, 21.0, 55.0, 71.0, 21.0, 28.0, 54.0, 28.0, 25.0, 24.0, 17.0, 21.0, 28.0, 37.0, 16.0, 18.0, 33.0, 28.0, 28.0, 26.0, 29.0, 28.0, 36.0, 54.0, 24.0, 47.0, 34.0, 28.0, 36.0, 32.0, 30.0, 22.0, 28.0, 44.0, 28.0, 40.5, 50.0, 28.0, 39.0, 23.0, 2.0, 28.0, 17.0, 28.0, 30.0, 7.0, 45.0, 30.0, 28.0, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, 28.0, 33.0, 8.0, 17.0, 27.0, 28.0, 22.0, 22.0, 62.0, 48.0, 28.0, 39.0, 36.0, 28.0, 40.0, 28.0, 28.0, 28.0, 24.0, 19.0, 29.0, 28.0, 32.0, 62.0, 53.0, 36.0, 28.0, 16.0, 19.0, 34.0, 39.0, 28.0, 32.0, 25.0, 39.0, 54.0, 36.0, 28.0, 18.0, 47.0, 60.0, 22.0, 28.0, 35.0, 52.0, 47.0, 28.0, 37.0, 36.0, 28.0, 49.0, 28.0, 49.0, 24.0, 28.0, 28.0, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, 28.0, 28.0, 28.0, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, 28.0, 80.0, 51.0, 32.0, 28.0, 9.0, 28.0, 32.0, 31.0, 41.0, 28.0, 20.0, 24.0, 2.0, 28.0, 0.75, 48.0, 19.0, 56.0, 28.0, 23.0, 28.0, 18.0, 21.0, 28.0, 18.0, 24.0, 28.0, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, 28.0, 43.0, 28.0, 40.0, 31.0, 70.0, 31.0, 28.0, 18.0, 24.5, 18.0, 43.0, 36.0, 28.0, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, 28.0, 25.0, 60.0, 52.0, 44.0, 28.0, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, 28.0, 24.0, 28.0, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, 28.0, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, 28.0, 25.0, 25.0, 29.0, 11.0, 28.0, 23.0, 23.0, 28.5, 48.0, 35.0, 28.0, 28.0, 28.0, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, 28.0, 41.0, 20.0, 36.0, 16.0, 51.0, 28.0, 30.5, 28.0, 32.0, 24.0, 48.0, 57.0, 28.0, 54.0, 18.0, 28.0, 5.0, 28.0, 43.0, 13.0, 17.0, 29.0, 28.0, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, 28.0, 16.0, 28.0, 28.0, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, 28.0, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, 28.0, 28.0, 1.0, 28.0, 62.0, 15.0, 0.83, 28.0, 23.0, 18.0, 39.0, 21.0, 28.0, 32.0, 28.0, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, 28.0, 35.0, 28.0, 28.0, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, 28.0, 41.0, 21.0, 48.0, 28.0, 24.0, 42.0, 27.0, 31.0, 28.0, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, 28.0, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, 28.0, 26.0, 32.0], \"type\": \"scatter\"}], {\"barmode\": \"overlay\", \"title\": \"Age distribution\", \"xaxis1\": {\"zeroline\": false, \"domain\": [0.0, 1.0], \"anchor\": \"y2\"}, \"yaxis1\": {\"position\": 0.0, \"domain\": [0.35, 1], \"anchor\": \"free\"}, \"yaxis2\": {\"domain\": [0, 0.25], \"showticklabels\": false, \"anchor\": \"x1\", \"dtick\": 1}, \"hovermode\": \"closest\", \"legend\": {\"traceorder\": \"reversed\"}}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "age_bf_imputation = train['Age'].dropna()\n",
    "\n",
    "# Impute the missing value with the median\n",
    "train['Age'] = train['Age'].fillna(train['Age'].median())\n",
    "\n",
    "hist_data = [age_bf_imputation, train['Age']]\n",
    "\n",
    "group_labels = ['Before imputation', 'After imputation']\n",
    "colors = ['#333F44', '#37AA9C']\n",
    "\n",
    "# Create distplot\n",
    "fig9 = FF.create_distplot(hist_data, group_labels, show_hist=False, colors=colors)\n",
    "\n",
    "#Add title\n",
    "fig9['layout'].update(title='Age distribution')\n",
    "\n",
    "# Plot\n",
    "iplot(fig9, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm missing values have been taken care of\n",
    "train['Age'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data - Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n"
     ]
    }
   ],
   "source": [
    "print(train['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embarked column also has missing values - nan. We impute the missing values with most common port of embarkation Southampton(S)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"84b16fe7-0457-428a-8eaf-4234b1cf896a\" style=\"height: 400px; width: 500px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"84b16fe7-0457-428a-8eaf-4234b1cf896a\", [{\"x\": [\"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"Q\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"C\", \"Q\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"C\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"C\", \"C\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"C\", \"C\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"C\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"C\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"Q\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"Q\"], \"type\": \"histogram\", \"name\": \"Before Imputation\", \"histnorm\": \"count\"}, {\"x\": [\"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"Q\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"C\", \"Q\", \"Q\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"C\", \"C\", \"C\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"C\", \"C\", \"S\", \"Q\", \"S\", \"C\", \"C\", \"Q\", \"C\", \"C\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"C\", \"C\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"C\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"Q\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"S\", \"Q\", \"C\", \"S\", \"C\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"Q\", \"Q\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"Q\", \"S\", \"Q\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"Q\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"C\", \"Q\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"C\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"S\", \"C\", \"C\", \"S\", \"S\", \"S\", \"C\", \"S\", \"S\", \"S\", \"S\", \"S\", \"Q\", \"S\", \"S\", \"S\", \"C\", \"Q\"], \"type\": \"histogram\", \"name\": \"After Imputation\"}], {\"autosize\": false, \"width\": 500, \"title\": \"Passenger distribution by Port of Embarkation\", \"height\": 400, \"barmode\": \"group\", \"bargap\": 0.5}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embarked_bf_imputation = go.Histogram(\n",
    "    x=train['Embarked'].dropna(),\n",
    "    histnorm='count',\n",
    "    name='Before Imputation',\n",
    ")\n",
    "\n",
    "# Impute the Embarked variable\n",
    "train['Embarked'] = train['Embarked'].fillna('S')\n",
    "\n",
    "embarked_af_imputation = go.Histogram(\n",
    "    x=train['Embarked'],\n",
    "    name = 'After Imputation'\n",
    ")\n",
    "\n",
    "embarked_bf_af_imputation = [embarked_bf_imputation, embarked_af_imputation]\n",
    "\n",
    "#Layout\n",
    "layout = go.Layout(autosize = False, width = 500, height = 400, bargap = 0.5,\n",
    "                  barmode='group',\n",
    "                  title = 'Passenger distribution by Port of Embarkation')\n",
    "\n",
    "fig10 = go.Figure(data=embarked_bf_af_imputation, layout = layout)\n",
    "\n",
    "#Plot\n",
    "iplot(fig10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the increase in passenger number from 644 to 646 in Southampton(S) port after imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm missing values from Embarked column have been taken care of\n",
    "train['Embarked'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert non-numeric columns - Sex and Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex and Embarked variable are categorical, but in non-numeric format. We will have to convert non-numeric columns to numeric ones so that classifier can handle it. To do so, we have to find unique classes in non-numeric column and encode each class a unique integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    }
   ],
   "source": [
    "print(train['Sex'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Convert categorical variable Sex to integer form\n",
    "sex_to_integers = {'male':0, 'female':1}\n",
    "train['Sex'] = train['Sex'].apply(sex_to_integers.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q']\n"
     ]
    }
   ],
   "source": [
    "print(train['Embarked'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert categorical variable Embarked to integer form\n",
    "embarked_to_integers = {'S':0, 'C':1, 'Q':2}\n",
    "train['Embarked'] = train['Embarked'].apply(embarked_to_integers.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How accurately can we predict survival based on available features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case, the dependent variable is categorical. We only care about two outcomes either 0(deceased) or 1(survived). Logistic regression uses a logit function to squeeze the output values to 0 or 1.\n",
    "\n",
    "Sklearn has a class for logistic regression that we can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and the 95% confidence interval of the estimate are: 0.788 (+/- 0.79)\n"
     ]
    }
   ],
   "source": [
    "# Import the `LogisticRegression` and cross validation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# The features we'll use to predict survival\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Initialize our algorithm\n",
    "logreg = LogisticRegression(random_state=1)\n",
    "\n",
    "# Compute the accuracy score for all the cross validation folds.  \n",
    "scores = cross_validation.cross_val_score(logreg, train[predictors], train[\"Survived\"], cv=3)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print \"Accuracy and the 95% confidence interval of the estimate are: {0:.3f} (+/- {0:.2f})\".format( \\\n",
    "       scores.mean(), scores.std() * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One parameter used in the evaluation of classification algorithm is accuracy. Accuracy measures the fraction of items in a class labelled correctly. We obtained an accuracy of 78.8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest fits multiple (very deep) classification trees with slightly randomized input data, and slightly randomized split points using the training set. It uses averaging to improve the predictive accuracy and control over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the `RandomForestClassifier`\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "#Build our forest\n",
    "forest = RandomForestClassifier(max_depth = 10, min_samples_split=2, n_estimators = 25, random_state = 1)\n",
    "forest.fit( train[predictors], train[\"Survived\"])\n",
    "feature_importances = forest.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"58479711-4bf6-4826-b490-c708002abda8\" style=\"height: 400px; width: 400px;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"58479711-4bf6-4826-b490-c708002abda8\", [{\"y\": [0.10260540873377783, 0.3218813333117065, 0.20473761953641426, 0.05267089638725093, 0.039886902168756115, 0.2393011500729326, 0.038916689789161844], \"x\": [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"], \"type\": \"bar\"}], {\"height\": 400, \"width\": 400, \"autosize\": false, \"yaxis\": {\"title\": \"Importance\"}, \"title\": \"Importance of features\"}, {\"linkText\": \"Export to plot.ly\", \"showLink\": true})});</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can also do offline plotting using plotly\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, iplot\n",
    "\n",
    "# Initiate the Plotly Notebook mode for plotting graphs offline inside a Jupyter Notebook Environment\n",
    "#Run at the start of every ipython notebook to use plotly.offline. \n",
    "#This injects the plotly.js source files into the notebook.\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "#Plot the importance of each feature\n",
    "feature_data = [go.Bar(\n",
    "            x=predictors,\n",
    "            y=feature_importances\n",
    "    )]\n",
    "\n",
    "feature_layout = go.Layout(autosize = False, width = 400, height = 400,\n",
    "                  yaxis = dict(title = 'Importance'),\n",
    "                  title = 'Importance of features')\n",
    "fig11 = go.Figure(data = feature_data, layout = feature_layout)\n",
    "iplot(fig11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and the 95% confidence interval of the estimate are: 0.825 (+/- 0.82)\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy score for all the cross validation folds. \n",
    "kf = cross_validation.KFold(train.shape[0], n_folds=3, random_state=1)\n",
    "scores = cross_validation.cross_val_score(forest, train[predictors], train[\"Survived\"], cv=kf)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print \"Accuracy and the 95% confidence interval of the estimate are: {0:.3f} (+/- {0:.2f})\".format( \\\n",
    "       scores.mean(), scores.std() * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We have built a useful classifier for predicting the survival of passengers aboard the RMS Titanic. We also saw that Sex, Fare, Age and Pclass are the four most important features in determining the survivors of the ship sinking. The accuracy of our random forest classifier is 82.5%. Also we measured the accuracy of our classifier on the same dataset we trained it on. It will be interesting to see how well our classifier performs on the test dataset. Similarly, it is important to evaluate our classifiers based on other metrics namely, Precision and Recall. Precision measures the  results relevancy, whereas recall measures how many truly relevant results are returned. \n",
    "\n",
    "We can improve the accuracy for our algorithm by engineering new features. Feature engineering involves creatively combining different variables to engineer a new one.\n",
    "Title of the passenger from their names. Were any particular title more likely to survive?\n",
    "Family size from variables SibSp and Parch. Did having more women and children in the family made the whole family more likely to survive?\n",
    "\n",
    "There are limitations with the dataset too. There were several missing values in the 'Age' column and 'Embarked' column. We did our best approximation to fill in the missing values, however, our approxiation might be biasing the prediction. In addition the dataset contained information about 891 out of 2224 passengers and crew abroad. Even when combined with 418 passengers information, the numbers still don't add upto 2224. Also, the current data doesn't distinguish between passengers and crew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1) [Udacity's Intro to Data Analysis](https://www.udacity.com/course/intro-to-data-analysis--ud170)\n",
    "<br \\>2) [Plotly](https://plot.ly/python/)\n",
    "<br \\>3) [Titanic Survival Exploration](https://github.com/udacity/Project-Descriptions-for-Review/blob/master/Machine-Learning/Titanic%20Survival%20Exploration.md)\n",
    "<br \\>4) [sklearn](http://scikit-learn.org/stable/)\n",
    "<br \\>5) [Kaggle Titanic](https://www.kaggle.com/c/titanic)\n",
    "<br \\>6) [Udacity's Intro to Machine Learning](https://www.udacity.com/course/intro-to-machine-learning--ud120)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
